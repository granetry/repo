# generates a scatter plot for q
q + geom_point()
# binds our variables of interest, engine size and highway milage
q = ggplot(data=mpg,
mapping=aes(x=displ, y=hwy, size=class))
# generates a scatter plot for q
q + geom_point()
# binds our variables of interest, engine size and highway milage
q = ggplot(data=mpg,
mapping=aes(x=displ, y=hwy, shape=class))
# generates a scatter plot for q
q + geom_point()
# binds our variables of interest, engine size and highway milage
q = ggplot(data=mpg,
mapping=aes(x=displ, y=hwy, color=class))
# generates a scatter plot for q
q + geom_point()
library(ggplot2)
d = diamonds
j = ggplot(d, mapping = aes(x = carat,y = price, color = cut,  alpha = 0.1)) +
theme_bw() +
scale_x_log10() +
facet_wrap(~ clarity) +
geom_point() +
labs(title = 'Carat vs Price')
# geom_smooth -> 'gam' is linear.
j + geom_smooth(method = 'gam', col = 'darkorange')
# this is the best for small data sets but is computationally inefficient
p + geom_point() + geom_smooth(method='loess', colour='red')
# log scaling to spread the data better
p + geom_point() +
geom_smooth(method='lm') +
scale_x_log10(labels = scales::dollar)
?dollar
p <- ggplot(data = gapminder,
mapping = aes(x = gdpPercap, y = lifeExp, color = 'yellow'))
p + geom_point() + scale_x_log10()
p <- ggplot(data = gapminder,
mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point(color = 'yellow') + scale_x_log10()
library(scales)
p <- ggplot(data = gapminder,
mapping = aes(x = gdpPercap, y = lifeExp, color = continent, fill = continent))
p + geom_point()
p + geom_point() + scale_x_log10(labels = dollar)
p + geom_point() + scale_x_log10(labels = dollar) + geom_smooth()
p <- ggplot(data = gapminder,
mapping = aes(x = gdpPercap, y = lifeExp, color = continent, fill = continent))
p + geom_point() + scale_x_log10(labels = dollar) + geom_smooth()
p <- ggplot(data = gapminder,
mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point(colour='yellow') + scale_x_log10()
p <- ggplot(data = gapminder,
mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point() +
geom_smooth(color = "orange", se = FALSE, size = 8, method = "lm") +
scale_x_log10()
p + geom_point(alpha = 0.3) +
geom_smooth(method = "gam") +
scale_x_log10(labels = scales::dollar) +
labs(x = "GDP Per Capita", y = "Life Expectancy in Years",
title = "Economic Growth and Life Expectancy",
subtitle = "Data Points are country-years",
caption = "Source: Gapminder")
p <- ggplot(data = gapminder,
mapping = aes(x = gdpPercap, y = lifeExp, color = continent, fill = continent))
p + geom_point()
p + geom_point() + scale_x_log10(labels = dollar)
p + geom_point() + scale_x_log10(labels = dollar) + geom_smooth()
p + geom_point(alpha=0.3) + scale_x_log10(labels = dollar) + geom_smooth()
p <- ggplot(data = gapminder,
mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point(mapping = aes(color = continent)) + geom_smooth() + scale_x_log10()
p <- ggplot(data = gapminder,
mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point(mapping = aes(color = continent)) +
geom_smooth(mapping = aes(color = continent, fill = continent)) +
scale_x_log10() +
geom_smooth(mapping = aes(color = continent), method = "gam")
p <- ggplot(data = gapminder,
mapping = aes(x = gdpPercap, y = lifeExp, color=continent, fill=continent))
p + geom_point() +
geom_smooth() +
scale_x_log10() +
geom_smooth(method = "gam")
---
title: "SSC442_Lab_1_E2"
output:
pdf_document:
latex_engine: lualatex
html_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
cache = TRUE)
```
```{r, echo=FALSE, include=FALSE}
library(readr)
library(tidyverse)
library(ggplot2)
library(scales)
urlfile = 'https://raw.githubusercontent.com/MSUDataAnalytics/SSC442/master/Labs/data/bank.csv'
bank = read_csv(url(urlfile))
head(bank)
sub_data = bank[bank$y=='yes',]
```
# Bank Analysis
## Introduction and Methodology
This memo focuses on two subsets of banking data that help to capture the makeup of those who did and did not choose to subscribe to the long-term savings program. By subsetting our data we're able to find the differences in those who opt in and those who don't which will further allow for better marketing in the future. The analysis is performed using a range of variables that show some correlation. These are balance and job type colored by education and balance and campaign calls colored by previous marketing.
## Balance and Education
```{r, echo=FALSE, out.width='50%'}
S_balance_education = ggplot(data=sub_data,
mapping=aes(x=job, y=balance, color = education))
A_balance_education = ggplot(data=bank,
mapping=aes(x=job, y=balance, color = education))
s_plot_b_e = S_balance_education + geom_jitter() +
theme(axis.text.x = element_text(angle = 60, hjust = 1))
a_plot_b_e = A_balance_education + geom_jitter() +
theme(axis.text.x = element_text(angle = 60, hjust = 1))
s_plot_b_e
a_plot_b_e
```
Above we have a plot showing balance by job type colored by education. The data being fed into this plot is of those who opted in to the product. We highlight the density of the blue-collar, management, and technician customers. By more heavily targetting these groups there should be an increase in subscribers to the surface. The following graph shows a relatively homogenous spread of characteristics between jobs, meaning that our prediction of increased subscribers from these groups should hold when scaled up.
## Campaign and Balance
```{r, echo=FALSE, out.width='50%'}
S_balance_duration = ggplot(data=sub_data,
mapping = aes(x=campaign, y=balance, color=previous))
A_balance_duration = ggplot(data=bank,
mapping = aes(x=campaign, y=balance, color=previous))
s_plot_b_d = S_balance_duration + geom_point()
a_plot_b_d = A_balance_duration + geom_point()
s_plot_b_d
a_plot_b_d
```
The above plot shows the patterns derived from campaign efforts and balance. You'll notice by comparison that those who opted in typically have far lower balances than those who did not. It also shows that the marketing efforts typically have little effect after the first 3 attempts and no effect after the first 10 attempts. Our recomendation is to taret those with lower balances and to respect the customers answer after 3-5 attempts. This should help to reduce the time and money spent marketing to customers that have made up there mind.
## Conclusion
Our memo shows correlations between some interesting variables focusing on the type of customer who opts in and the campaigning effectiveness. We believe implementing the suggestion above will help to better target customers who are interested in the product and save money on over-marketing to those who have made up their mind on the product. With more data on the marketing timing we may be able to gain insight into the best time to market to customers, however this data set was able to provide a strong base for changes.
# Bank Analysis
## Introduction and Methodology
This memo focuses on two subsets of banking data that help to capture the makeup of those who did and did not choose to subscribe to the long-term savings program. By subsetting our data we're able to find the differences in those who opt in and those who don't which will further allow for better marketing in the future. The analysis is performed using a range of variables that show some correlation. These are balance and job type colored by education and balance and campaign calls colored by previous marketing.
## Balance and Education
```{r, echo=FALSE, out.width='50%'}
S_balance_education = ggplot(data=sub_data,
mapping=aes(x=job, y=balance, color = education))
A_balance_education = ggplot(data=bank,
mapping=aes(x=job, y=balance, color = education))
s_plot_b_e = S_balance_education + geom_jitter() +
theme(axis.text.x = element_text(angle = 60, hjust = 1))
a_plot_b_e = A_balance_education + geom_jitter() +
theme(axis.text.x = element_text(angle = 60, hjust = 1))
s_plot_b_e
a_plot_b_e
```
Above we have a plot showing balance by job type colored by education. The data being fed into this plot is of those who opted in to the product. We highlight the density of the blue-collar, management, and technician customers. By more heavily targetting these groups there should be an increase in subscribers to the surface. The following graph shows a relatively homogenous spread of characteristics between jobs, meaning that our prediction of increased subscribers from these groups should hold when scaled up.
## Campaign and Balance
```{r, echo=FALSE, out.width='50%'}
S_balance_duration = ggplot(data=sub_data,
mapping = aes(x=campaign, y=balance, color=previous))
A_balance_duration = ggplot(data=bank,
mapping = aes(x=campaign, y=balance, color=previous))
s_plot_b_d = S_balance_duration + geom_point()
a_plot_b_d = A_balance_duration + geom_point()
s_plot_b_d
a_plot_b_d
```
The above plot shows the patterns derived from campaign efforts and balance. You'll notice by comparison that those who opted in typically have far lower balances than those who did not. It also shows that the marketing efforts typically have little effect after the first 3 attempts and no effect after the first 10 attempts. Our recomendation is to taret those with lower balances and to respect the customers answer after 3-5 attempts. This should help to reduce the time and money spent marketing to customers that have made up there mind.
## Conclusion
Our memo shows correlations between some interesting variables focusing on the type of customer who opts in and the campaigning effectiveness. We believe implementing the suggestion above will help to better target customers who are interested in the product and save money on over-marketing to those who have made up their mind on the product. With more data on the marketing timing we may be able to gain insight into the best time to market to customers, however this data set was able to provide a strong base for changes.
ggplot(d, aes(x = carat,y = price, fill = carat, alpha = 1)) +
theme_bw() +
facet_wrap(~ clarity) +
geom_point() +
labs(title = 'Carat vs Price')
p <- ggplot(data = gapminder,
mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point() +
geom_smooth(color = "orange", se = FALSE, size = 8, method = "lm") +
scale_x_log10()
p + geom_point(alpha = 0.3) +
geom_smooth(method = "gam") +
scale_x_log10(labels = scales::dollar) +
labs(x = "GDP Per Capita", y = "Life Expectancy in Years",
title = "Economic Growth and Life Expectancy",
subtitle = "Data Points are country-years",
caption = "Source: Gapminder")
p <- ggplot(data = gapminder,
mapping = aes(x = gdpPercap, y = lifeExp, color = continent, fill = continent))
p + geom_point()
p + geom_point() + scale_x_log10(labels = dollar)
p + geom_point() + scale_x_log10(labels = dollar) + geom_smooth()
p + geom_point(alpha=0.3) + scale_x_log10(labels = dollar) + geom_smooth()
p <- ggplot(data = gapminder,
mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point(mapping = aes(color = continent)) +
geom_smooth(mapping = aes(color = continent, fill = continent)) +
scale_x_log10() +
geom_smooth(mapping = aes(color = continent), method = "gam")
p <- ggplot(data = gapminder,
mapping = aes(x = gdpPercap, y = lifeExp, color=continent, fill=continent))
p + geom_point() +
geom_smooth() +
scale_x_log10() +
geom_smooth(method = "gam")
library(ggplot2)
# Load the Titanic titanicing data for analysis.
titanic <- read.csv('titanic.csv', stringsAsFactors = FALSE)
# Open data in speadsheet view.
View(titanic)
# Load the Titanic titanicing data for analysis.
titanic <- read.csv('titanic.csv', stringsAsFactors = FALSE)
(tidyverse)
library(tidyverse)
library(ggplot2)
library(gapminder)
library(scales)
ggplot2::mpg
# generates gapminder data set
head(gapminder)
# binds our variables of interest, gpdpercap and life exp
p = ggplot(data=gapminder,
mapping=aes(x=gdpPercap, y=lifeExp))
# generates a scatter plot for p
p + geom_point()
# binds our variables of interest, engine size and highway milage
q = ggplot(data=mpg,
mapping=aes(x=displ, y=hwy, color=class))
# generates a scatter plot for q
q + geom_point()
library("plot3D")
x = autompg$wt
y = autompg$year
# read the data from the web
autompg = read.table(
"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data",
quote = "\"",
comment.char = "",
stringsAsFactors = FALSE)
# give the dataframe headers
colnames(autompg) = c("mpg", "cyl", "disp", "hp", "wt", "acc", "year", "origin", "name")
# remove missing data, which is stored as "?"
autompg = subset(autompg, autompg$hp != "?")
# remove the plymouth reliant, as it causes some issues
autompg = subset(autompg, autompg$name != "plymouth reliant")
# give the dataset row names, based on the engine, year and name
rownames(autompg) = paste(autompg$cyl, "cylinder", autompg$year, autompg$name)
# remove the variable for name, as well as origin
autompg = subset(autompg, select = c("mpg", "cyl", "disp", "hp", "wt", "acc", "year"))
# change horsepower from character to numeric
autompg$hp = as.numeric(autompg$hp)
# check final structure of data
str(autompg)
# create local csv for backup
write.csv(autompg, "data/autompg.csv")
library("plot3D")
x = autompg$wt
y = autompg$year
z = autompg$mpg
fit <- lm(z ~ x + y)
grid.lines = 25
x.pred     = seq(min(x), max(x), length.out = grid.lines)
y.pred     = seq(min(y), max(y), length.out = grid.lines)
xy         = expand.grid(x = x.pred, y = y.pred)
z.pred = matrix(predict(fit, newdata = xy),
nrow = grid.lines, ncol = grid.lines)
fitpoints = predict(fit)
scatter3D(x, y, z, pch = 19, cex = 2, col = gg.col(1000), lighting = TRUE,
theta = 25, phi = 45, ticktype = "detailed",
xlab = "wt", ylab = "year", zlab = "mpg", zlim = c(0, 40), clim = c(0, 40),
surf = list(x = x.pred, y = y.pred, z = z.pred,
facets = NA, fit = fitpoints), main = "")
install.packages("plot3D")
library("plot3D")
x = autompg$wt
y = autompg$year
z = autompg$mpg
fit <- lm(z ~ x + y)
grid.lines = 25
x.pred     = seq(min(x), max(x), length.out = grid.lines)
y.pred     = seq(min(y), max(y), length.out = grid.lines)
xy         = expand.grid(x = x.pred, y = y.pred)
z.pred = matrix(predict(fit, newdata = xy),
nrow = grid.lines, ncol = grid.lines)
fitpoints = predict(fit)
scatter3D(x, y, z, pch = 19, cex = 2, col = gg.col(1000), lighting = TRUE,
theta = 25, phi = 45, ticktype = "detailed",
xlab = "wt", ylab = "year", zlab = "mpg", zlim = c(0, 40), clim = c(0, 40),
surf = list(x = x.pred, y = y.pred, z = z.pred,
facets = NA, fit = fitpoints), main = "")
mpg_model = lm(mpg ~ wt + year, data = autompg)
coef(mpg_model)
mpg_model = lm(mpg ~ wt + year, data = autompg)
coef(mpg_model)
n = nrow(autompg)
p = length(coef(mpg_model))
X = cbind(rep(1, n), autompg$wt, autompg$year)
y = autompg$mpg
(beta_hat = solve(t(X) %*% X) %*% t(X) %*% y)
coef(mpg_model)
summary(mpg_model)$sigma
y_hat = X %*% solve(t(X) %*% X) %*% t(X) %*% y
e     = y - y_hat
sqrt(t(e) %*% e / (n - p))
sqrt(sum((y - y_hat) ^ 2) / (n - p))
summary(mpg_model)
summary(mpg_model)$coef
confint(mpg_model, level = 0.99)
new_cars = data.frame(wt = c(3500, 5000), year = c(76, 81))
new_cars
predict(mpg_model, newdata = new_cars, interval = "confidence", level = 0.99)
new_cars$wt
range(autompg$wt)
new_cars$year
range(autompg$year)
plot(year ~ wt, data = autompg, pch = 20, col = "dodgerblue", cex = 1.5)
points(new_cars, col = "darkorange", cex = 3, pch = "X")
x0 = c(1, 3500, 76)
x0 %*% beta_hat
beta_hat
x0 = c(0, 0, 1)
x0 %*% beta_hat
new_cars
predict(mpg_model, newdata = new_cars, interval = "prediction", level = 0.99)
summary(mpg_model)$r.squared
summary(mpg_model)$r.squared
null_mpg_model = lm(mpg ~ 1, data = autompg)
full_mpg_model = lm(mpg ~ wt + year, data = autompg)
anova(null_mpg_model, full_mpg_model)
summary(mpg_model)
# SSReg
sum((fitted(full_mpg_model) - fitted(null_mpg_model)) ^ 2)
# SSE
sum(resid(full_mpg_model) ^ 2)
# SST
sum(resid(null_mpg_model) ^ 2)
# Degrees of Freedom: Regression
length(coef(full_mpg_model)) - length(coef(null_mpg_model))
# Degrees of Freedom: Error
length(resid(full_mpg_model)) - length(coef(full_mpg_model))
# Degrees of Freedom: Total
length(resid(null_mpg_model)) - length(coef(null_mpg_model))
anova(null_mpg_model, full_mpg_model)
null_mpg_model = lm(mpg ~ wt + year, data = autompg)
#full_mpg_model = lm(mpg ~ wt + year + cyl + disp + hp + acc, data = autompg)
full_mpg_model = lm(mpg ~ ., data = autompg)
anova(null_mpg_model, full_mpg_model)
set.seed(1337)
n = 100 # sample size
p = 3
beta_0 = 5
beta_1 = -2
beta_2 = 6
sigma  = 4
anova(null_mpg_model, full_mpg_model)
x0 = rep(1, n)
x1 = sample(seq(1, 10, length = n))
x2 = sample(seq(1, 10, length = n))
X = cbind(x0, x1, x2)
C = solve(t(X) %*% X)
eps      = rnorm(n, mean = 0, sd = sigma)
y        = beta_0 + beta_1 * x1 + beta_2 * x2 + eps
sim_data = data.frame(x1, x2, y)
# make this use data.frame? or, simply hide this?
fit = lm(y ~ x1 + x2)
grid.lines = 25
x1.pred = seq(min(x1), max(x1), length.out = grid.lines)
x2.pred = seq(min(x2), max(x2), length.out = grid.lines)
x1x2 = expand.grid(x1 = x1.pred, x2 = x2.pred)
y.pred = matrix(predict(fit, newdata = x1x2),
nrow = grid.lines, ncol = grid.lines)
# fitted points for droplines to surface
fitpoints = predict(fit)
# scatter plot with regression plane
scatter3D(x1, x2, y, pch = 20, cex = 2, col = gg.col(1000), lighting = TRUE,
theta = 45, phi = 15, ticktype = "detailed", zlim = c(min(y.pred), max(y.pred)), clim = c(min(y.pred), max(y.pred)),
xlab = "x1", ylab = "x2", zlab = "y",
surf = list(x = x1.pred, y = x2.pred, z = y.pred,
facets = NA, fit = fitpoints), main = "")
bank = read.csv('bank.csv')
bank = read.csv('bank.csv')
bank = read.csv('bank.csv')
bank_data= 'https://raw.githubusercontent.com/MSUDataAnalytics/SSC442/master/Labs/data/bank.csv'
bank_data
head(bank_data)
banks = read.csv(url(bank_data)
banks
banks = read.csv(url(bank_data)
head(banks)
banks = read.csv(url(bank_data)
bank_data= 'https://raw.githubusercontent.com/MSUDataAnalytics/SSC442/master/Labs/data/bank.csv'
bank_data= 'https://raw.githubusercontent.com/MSUDataAnalytics/SSC442/master/Labs/data/bank.csv'
banks = read.csv(url(bank_data)
banks = read.csv(url('bank_data')
bank_data= 'https://raw.githubusercontent.com/MSUDataAnalytics/SSC442/master/Labs/data/bank.csv'
bank = read.csv(url('bank_data')
head(bank)
bank = read.csv(url(bank_data)
head(bank)
bank = read.csv(url(bank_data))
head(bank)
view(bank)
View(bank)
name(bank)
Name(bank)
col(bank)
bank_model = lm(balance ~ job + marital + education + housing + loan + contact + day + month + duration + compaign, data = banks)
bank_model = lm(balance ~ job + marital + education + housing + loan + contact + day + month + duration + compaign, data = bank)
bank_model = lm(balance ~ job + marital + education + housing + loan + contact + day + month + duration + campaign, data = bank)
bank_model
full_bank_model = lm(balance ~ ., data = bank)
full_bank_model
summary(full_bank_model
)
summary(full_bank_model
summary(full_bank_model)
summary(full_bank_model)
new_bank_model = lm(balance ~ !bank$job)
new_bank_model = lm(balance ~ !bank$job, data = bank)
library(ggplot2)
p = ggplot('bank.csv')
bank = read.csv('bank')
bank = read.csv(bank_data)
bank_data = 'https://raw.githubusercontent.com/MSUDataAnalytics/SSC442/master/Labs/data/bank.csv'
bank = read.csv(bank_data)
head(bank)
View(bank)
p = ggplot(bank, mapping = aes(x = age, y = balance))
p + geom_point()
p + geom_point() + facet_wrap(~ job)
p + geom_point() + facet_wrap(~ job) + scale_x_log10()
p + geom_point() + facet_wrap(~ job)
p + geom_point() + facet_wrap(~ job) + scale_x_log10()
p + geom_histogram(binwidth = 1)
g = ggplot(data = bank, y = balance)
g + geom_histogram(binwidth = 1)
g = ggplot(data = bank, x = balance)
g + geom_histogram(binwidth = 1)
g = ggplot(data = bank, x = balance)
g + geom_histogram(binwidth = 1)
g = ggplot(data = bank, mapping = aes(x = balance))
g + geom_histogram(binwidth = 1)
g + geom_histogram(binwidth = 1000)
g = ggplot(data = bank, aes(x = balance))
g + geom_histogram(binwidth = 1000)
g + geom_histogram(binwidth = 500)
g + geom_histogram(binwidth = 100)
g + geom_histogram(binwidth = 100) + facet_wrap(~ job)
g + geom_histogram(binwidth = 100) + facet_wrap(~ job) + scale_x_log10()
g + geom_histogram(binwidth = 1) + facet_wrap(~ job) + scale_x_log10()
g + geom_histogram(binwidth = 1) + facet_wrap(~ job) + scale_x_log10(label= dollars)
g + geom_histogram(binwidth = 1) + facet_wrap(~ job) + scale_x_log10(label= dollar)
library(ggplot2)
d = diamonds
View(d)
j = ggplot(d, mapping = aes(x = carat,y = price, color = cut,  alpha = 0.1)) +
theme_bw() +
scale_x_log10() +
facet_wrap(~ clarity) +
geom_point() +
labs(title = 'Carat vs Price')
# geom_smooth -> 'gam' is linear.
j + geom_smooth(method = 'gam', col = 'darkorange')
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = TRUE,
sep = ",")
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = TRUE,
sep = ",")
View(ameslist)
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = FALSE,
sep = ",")
View(ameslist)
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
sep = ",")
read.table
read.table(ameslist)
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = FALSE,
sep = ",")
read.table(ameslist)
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = TRUE,
sep = ",")
read.table(ameslist)
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = TRUE,
sep = ",")
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = FALSE,
sep = ",")
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = FALSE,
sep = ",")
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = TRUE,
sep = ",")
type(ameslist)
?read.table
read.table(ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = TRUE,
sep = ","))
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = TRUE,
sep = ",")
names(ameslist)
d = ameslist$SalePrice
head(d)
ameslist$SalePrice
# load raw data
train <- read.csv('train.csv', header = TRUE)
# load raw data
train <- read.csv('train.csv', header = TRUE)
